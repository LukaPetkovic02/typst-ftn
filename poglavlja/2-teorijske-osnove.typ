= Теоријске основе

== Хаотични системи

Хаотични системи представљају класу динамичких система чије се понашање карактерише изузетном осетљивошћу 
на почетне услове. Иако се њихова еволуција управља детерминистичким једначинама, 
и најмања промена у почетним параметрима доводи до драстичних промена резултата. 
Овај феномен је познат као *ефекат лептира* (_butterfly effect_) и чини да такви системи делују непредвидиво на дуже стазе.

Двоструко клатно је један од најпознатијих примера хаотичног система у класичној механици. 
Упркос томе што се заснива на једноставним законима физике, 
његово кретање може бити веома сложено, са путањама које се ретко понављају. 
Овакав систем је од посебног значаја у нумеричкој анализи, јер омогућава тестирање стабилности, 
тачности и перформанси различитих метода интеграције.

== Физички модел двоструког клатна

Двоструко клатно се састоји од два сегмента дужина _l₁_ и _l₂_, са масама _m₁_ и _m₂_. 
Први сегмент је окачен о фиксну тачку, док је други сегмент окачен на крај првог. 
Положај система описује се угловима _θ₁_ и _θ₂_ у односу на вертикалу.
Систем ћемо посматрати у две димензије због једноставности, а сем тога, занемарићемо све стране силе попут силе отпора ваздуха или силе трења.

Енергија система се састоји од кинетичке (_T_) и потенцијалне (_V_) енергије:

$E = T + V$

Кинетичка енергија:

$T = 1/2 m_1 (l_1 ω_1)^2 + 1/2 m_2 [ (l_1 ω_1)^2 + (l_2 ω_2)^2 + 2 l_1 l_2 ω_1 ω_2 cos(θ_1 - θ_2) ]$

Први члан се односи на кинетичку енергију горњег клатна.
Други члан се односи на кинетичку енергију доњег клатна које укључује:
- сопствено кретање
- кретање због ротације горњег сегмента
- међусобни унакрсни члан који настаје јер се вектори брзина не поклапају у правцу

Потенцијална енергија:

$V = -m_1 g l_1 cos(θ_1) - m_2 g [ l_1 cos(θ_1) + l_2 cos(θ_2) ]$

Потенцијална енергија се рачуна у односу на најнижи положај. Први члан се односи на висину масе _m₁_, а други на висину масе _m₂_ која зависи од оба угла.
Знак минус стоји испред јер се енергија система смањује кад тела иду надоле.

Ове једначине немају аналитичко решење, па се у пракси примењују нумеричке методе.

== Нумеричке методе интеграције

Када кажемо да систем „нема аналитичко решење“, то значи да не постоји затворени математички израз 
који би омогућио да се вредности променљивих добију директним рачунањем. 
Другим речима, функције које описују кретање тела не могу се изразити у облику једноставних формула 
(попут синуса, косинуса или експоненцијалa), већ се решење мора приближно израчунати.

Због тога се у пракси користе *нумеричке методе интеграције*, које омогућавају 
приближно решавање система диференцијалних једначина у малим временским корацима.  
Оне омогућавају да се за познато почетно стање система — 
почетне углове (_θ₁, θ₂_) и угаоне брзине (_ω₁, ω₂_) — 
израчунају нове вредности у наредним корацима времена (_t + Δt_).

Једноставне методе, попут Euler-ове, често производе велике грешке 
јер користе само једну процену нагиба функције у датом кораку. 
То доводи до акумулације грешке и нестабилности током дужих симулација, 
посебно код хаотичних система попут двоструког клатна.

Да би се добила већа тачност без већег повећања сложености, 
у овом раду примењује се *метода Рунге–Кута четвртог реда (RK4)*.  
Ова метода представља компромис између једноставности имплементације и нумеричке стабилности.  
Основна идеја је да се нова вредност израчунава на основу комбинације више процена нагиба унутар једног корака, 
што повећава тачност у односу на једноставније методе.

Ако је општа форма једначине:

$frac(d y, d t) = f(t, y)$

онда се алгоритам RK4 дефинише на следећи начин:

$k_1 = f(t, y)$

$k_2 = f(t + 1/2 h, y + 1/2 h k_1)$ 

$k_3 = f(t + 1/2 h, y + 1/2 h k_2)$  

$k_4 = f(t + h, y + h k_3)$  

$y_{n+1} = y_n + 1/6 h (k_1 + 2k_2 + 2k_3 + k_4)$

#figure(
  image("../slike/runge-kutta.png", width: 70%),
  caption: [
    Приказ Runge–Kutta (RK4) метода
  ]
)<fig:rk4>

На слици је приказано како се у сваком
кораку интеграције израчунавају четири различите процене нагиба 
($k_1$, $k_2$, $k_3$, $k_4$) које заједно дају бољу апроксимацију 
правог решења функције $x(t)$. Тачке $t_0$, $t_0 + h/2$ и $t_1$ 
представљају положаје у времену у којима се израчунавају 
међурезултати. Коначна вредност $x_1$ добија се као комбинација ових нагиба са различитим тежинама.

Метода Рунге–Кута се показала као стабилна и ефикасна чак и код система 
са израженом нелинеарношћу и хаотичним понашањем, што је чини изузетно погодном за ову симулацију.

== Паралелизација и модели скалирања

Иако је _Runge–Kutta_ метода изузетно погодна за тачно нумеричко решавање 
система диференцијалних једначина, она по својој природи није лако паралелизујућа. 
Разлог је што сваки временски корак зависи од резултата претходног — 
да би се израчунало стање у тренутку $t_{n+1}$, потребно је да буде познато 
стање у тренутку $t_n$. Ово уводи секвенцијалну зависност у израчунавање, 
која ограничава могућност директног распоређивања задатка на више процесора.

Да би се ипак искористиле предности савремених вишејезгарних процесора, 
примењује се тзв. *ансамбл паралелизација*.  
Уместо да се једна симулација раздваја на мање делове, 
истовремено се покреће више независних симулација са различитим 
почетним условима (различите комбинације углова и угаоних брзина).  
На овај начин сваки процес или нит извршава потпуно независан ток израчунавања, 
а резултати се на крају обједињују ради анализе понашања система.

Оваква стратегија има два кључна циља:
- боље искоришћење рачунарских ресурса (сви процесорски језгри су активни);
- омогућавање статистичке анализе резултата на већем броју различитих почетних услова.

Да би се ефикасност паралелизације објективно проценила, 
користе се два класична модела скалирања: *јако скалирање* и *слабо скалирање*.

=== Јако скалирање

Јако скалирање подразумева извршавање истог задатка (фиксиране величине проблема) 
на различитом броју процесора.  
Циљ је да се измери убрзање које се постиже повећањем броја процесора:

$S_p = T_1 / T_p$

где је $T_1$ време извршавања на једном процесору, 
а $T_p$ време извршавања на $p$ процесора.

У идеалном случају, убрзање би требало да буде линеарно ($S_p = p$), 
али у пракси долази до одступања услед додатних трошкова 
синхронизације, преноса података и управљања нитима.

#figure(
  image("../slike/strong_scaling.svg", width: 70%),
  caption: [
    Јако скалирање
  ]
)<fig:strong_scaling>

=== Слабо скалирање

Слабо скалирање подразумева пропорционално повећање величине проблема 
са бројем процесора. У овом моделу, сваки процесор има приближно исти 
количински део посла као у случају једног процесора.  
Циљ је да време извршавања остане приближно константно:

$E_p = T_1 / T_p$

где $E_p$ представља ефикасност система за $p$ процесора.  
Добра имплементација треба да показује малу промену у времену извршавања 
када се величина проблема повећава у складу са бројем процесора.

#figure(
  image("../slike/weak_scaling.svg", width: 70%),
  caption: [
    Слабо скалирање
  ]
)<fig:weak_scaling>

Ови модели биће примењени у експериментима који следе, 
како би се проценила скалабилност имплементација у језицима _Python_, _Rust_ и _Go_.

=== Амдалов и Густафсонов закон

Ефикасност паралелних програма се не може повећавати неограничено.  
Чак и када се број процесора повећава, део програма који се не може 
паралелизовати поставља природно ограничење убрзања.  
Ово ограничење описује *Амдалов закон*:

$S_p = frac(1, (1 - f) + f / p)$

где је:
- $S_p$ – убрзање које се постиже коришћењем $p$ процесора,  
- $f$ – део програма који се може паралелизовати,  
- $(1 - f)$ – серијски део програма који мора бити извршен секвенцијално.

#figure(
  image("../slike/amdalov_zakon.png", width: 70%),
  caption: [
    Амдалов закон
  ]
)<fig:amdalov_zakon>

Из Амдаловог закона произилази да чак и ако је 95% програма паралелно,  
теоријски максимум убрзања није већи од 20×, без обзира на број процесора.  
Зато је у пракси важно минимизовати серијске делове програма 
и комуникационе трошкове између процеса.

Међутим, Амдалов модел се користи у случају фиксне величине проблема.  
У стварности, повећање броја процесора често омогућава решавање већих проблема 
у истом временском оквиру.  
Ову идеју описује *Густафсонов закон*:

$S_p = p - α (p - 1)$

где је:
- $S_p$ – постигнуто убрзање,  
- $p$ – број процесора,  
- $α$ – серијски удео извршавања (однос времена серијског дела и укупног времена)

#figure(
  image("../slike/gustafsonov_zakon.png", width: 70%),
  caption: [
    Густафсонов закон
  ]
)<fig:gustafsonov_zakon>

Густафсонов закон показује да се у пракси убрзање може приближити линеарном,  
ако се величина проблема повећава заједно са бројем процесора,  
што је карактеристично за *слабо скалирање*.  
Ово објашњење боље одражава реалне услове рада савремених система,  
када се повећање броја процесора користи за обраду већих количина података,  
а не само за брже извршавање истог посла.

Комбинацијом Амдаловог и Густафсоновог модела могуће је добити 
реалнију процену ефикасности паралелних система и боље разумети 
понашање симулација при повећању броја процесора.
